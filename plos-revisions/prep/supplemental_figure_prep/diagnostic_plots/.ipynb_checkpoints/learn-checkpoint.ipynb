{
 "metadata": {
  "name": "",
  "signature": "sha256:ddbd7ff243f517efeaf05ffff9d35d356819f8f789f6bd435601c5f7fa778720"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "bgl = pandas.read_csv('joined.csv')\n",
      "bgl.drop(['new', 'old', 'yield', 'seq', 'err1', '%err1', 'err2', '%err2', 'slope', 'std_err', 'R', 'note', 'kcat', 'km'],inplace=True,axis=1)\n",
      "bgl.set_index('sample', drop=True)\n",
      "bgl = bgl.dropna()\n",
      "bgl.tail(13)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sample</th>\n",
        "      <th>eff</th>\n",
        "      <th>total_score</th>\n",
        "      <th>fa_rep</th>\n",
        "      <th>hbond_sc</th>\n",
        "      <th>all_cst</th>\n",
        "      <th>tot_pstat_pm</th>\n",
        "      <th>tot_nlpstat_pm</th>\n",
        "      <th>tot_burunsat_pm</th>\n",
        "      <th>tot_hbond_pm</th>\n",
        "      <th>...</th>\n",
        "      <th>SR_5</th>\n",
        "      <th>SR_5_total_score</th>\n",
        "      <th>SR_5_fa_rep</th>\n",
        "      <th>SR_5_hbond_sc</th>\n",
        "      <th>SR_5_all_cst</th>\n",
        "      <th>SR_5_interf_E_1_2</th>\n",
        "      <th>SR_5_dsasa_1_2</th>\n",
        "      <th>SR_5_hbond_pm</th>\n",
        "      <th>SR_5_burunsat_pm</th>\n",
        "      <th>description</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>94 </th>\n",
        "      <td> w407r</td>\n",
        "      <td>    0.00</td>\n",
        "      <td>-426.02</td>\n",
        "      <td> 389.41</td>\n",
        "      <td>-61.69</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 162</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 74.41</td>\n",
        "      <td> 78.02</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 148.82</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> w407r_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>95 </th>\n",
        "      <td>  q19s</td>\n",
        "      <td>    0.00</td>\n",
        "      <td>-434.77</td>\n",
        "      <td> 385.74</td>\n",
        "      <td>-61.92</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 156</td>\n",
        "      <td> 431</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 71.55</td>\n",
        "      <td> 76.12</td>\n",
        "      <td>-1.28</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 143.11</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td>  q19s_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>96 </th>\n",
        "      <td> w399s</td>\n",
        "      <td>    0.00</td>\n",
        "      <td>-495.78</td>\n",
        "      <td> 319.37</td>\n",
        "      <td>-61.02</td>\n",
        "      <td> 0.04</td>\n",
        "      <td> 0.67</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 156</td>\n",
        "      <td> 432</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 39.87</td>\n",
        "      <td> 43.48</td>\n",
        "      <td>-1.50</td>\n",
        "      <td> 0.02</td>\n",
        "      <td>  79.73</td>\n",
        "      <td> 0.91</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> w399s_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>97 </th>\n",
        "      <td> p329w</td>\n",
        "      <td>    0.00</td>\n",
        "      <td>-404.15</td>\n",
        "      <td> 412.39</td>\n",
        "      <td>-61.01</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 160</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 83.12</td>\n",
        "      <td> 86.85</td>\n",
        "      <td>-1.14</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 166.24</td>\n",
        "      <td> 0.94</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> p329w_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98 </th>\n",
        "      <td> m323k</td>\n",
        "      <td>   12.48</td>\n",
        "      <td>-424.25</td>\n",
        "      <td> 393.23</td>\n",
        "      <td>-61.69</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 160</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.63</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.26</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> m323k_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>99 </th>\n",
        "      <td> g355a</td>\n",
        "      <td>   13.19</td>\n",
        "      <td>-440.90</td>\n",
        "      <td> 378.95</td>\n",
        "      <td>-61.90</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 159</td>\n",
        "      <td> 431</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 67.84</td>\n",
        "      <td> 71.63</td>\n",
        "      <td>-1.24</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 135.67</td>\n",
        "      <td> 0.94</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> g355a_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>100</th>\n",
        "      <td> v147s</td>\n",
        "      <td>   57.28</td>\n",
        "      <td>-424.78</td>\n",
        "      <td> 392.58</td>\n",
        "      <td>-61.05</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 159</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> v147s_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101</th>\n",
        "      <td> m261e</td>\n",
        "      <td>  701.56</td>\n",
        "      <td>-424.89</td>\n",
        "      <td> 392.60</td>\n",
        "      <td>-61.05</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 0.67</td>\n",
        "      <td> 160</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> m261e_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>102</th>\n",
        "      <td> t218a</td>\n",
        "      <td> 5518.30</td>\n",
        "      <td>-426.36</td>\n",
        "      <td> 392.22</td>\n",
        "      <td>-60.54</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 159</td>\n",
        "      <td> 429</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> t218a_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>103</th>\n",
        "      <td> e423s</td>\n",
        "      <td> 5711.86</td>\n",
        "      <td>-427.78</td>\n",
        "      <td> 392.92</td>\n",
        "      <td>-62.05</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 159</td>\n",
        "      <td> 431</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> e423s_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>104</th>\n",
        "      <td>  i91e</td>\n",
        "      <td> 6544.77</td>\n",
        "      <td>-426.67</td>\n",
        "      <td> 392.75</td>\n",
        "      <td>-61.05</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 0.67</td>\n",
        "      <td> 159</td>\n",
        "      <td> 430</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  i91e_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>105</th>\n",
        "      <td>  s17a</td>\n",
        "      <td> 7143.90</td>\n",
        "      <td>-427.07</td>\n",
        "      <td> 392.90</td>\n",
        "      <td>-61.48</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 0.70</td>\n",
        "      <td> 160</td>\n",
        "      <td> 428</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  s17a_0001</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>106</th>\n",
        "      <td> t175r</td>\n",
        "      <td> 8150.17</td>\n",
        "      <td>-426.74</td>\n",
        "      <td> 392.84</td>\n",
        "      <td>-61.48</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.69</td>\n",
        "      <td> 0.68</td>\n",
        "      <td> 158</td>\n",
        "      <td> 431</td>\n",
        "      <td>...</td>\n",
        "      <td> 446</td>\n",
        "      <td> 75.56</td>\n",
        "      <td> 79.31</td>\n",
        "      <td>-1.16</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 151.12</td>\n",
        "      <td> 0.95</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> t175r_0001</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>13 rows \u00d7 62 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 184,
       "text": [
        "    sample      eff  total_score  fa_rep  hbond_sc  all_cst  tot_pstat_pm  \\\n",
        "94   w407r     0.00      -426.02  389.41    -61.69     0.00          0.69   \n",
        "95    q19s     0.00      -434.77  385.74    -61.92     0.00          0.70   \n",
        "96   w399s     0.00      -495.78  319.37    -61.02     0.04          0.67   \n",
        "97   p329w     0.00      -404.15  412.39    -61.01     0.00          0.68   \n",
        "98   m323k    12.48      -424.25  393.23    -61.69     0.00          0.70   \n",
        "99   g355a    13.19      -440.90  378.95    -61.90     0.00          0.68   \n",
        "100  v147s    57.28      -424.78  392.58    -61.05     0.00          0.68   \n",
        "101  m261e   701.56      -424.89  392.60    -61.05     0.00          0.69   \n",
        "102  t218a  5518.30      -426.36  392.22    -60.54     0.00          0.69   \n",
        "103  e423s  5711.86      -427.78  392.92    -62.05     0.00          0.68   \n",
        "104   i91e  6544.77      -426.67  392.75    -61.05     0.00          0.69   \n",
        "105   s17a  7143.90      -427.07  392.90    -61.48     0.00          0.70   \n",
        "106  t175r  8150.17      -426.74  392.84    -61.48     0.00          0.69   \n",
        "\n",
        "     tot_nlpstat_pm  tot_burunsat_pm  tot_hbond_pm      ...       SR_5  \\\n",
        "94             0.69              162           430      ...        446   \n",
        "95             0.70              156           431      ...        446   \n",
        "96             0.69              156           432      ...        446   \n",
        "97             0.69              160           430      ...        446   \n",
        "98             0.70              160           430      ...        446   \n",
        "99             0.69              159           431      ...        446   \n",
        "100            0.68              159           430      ...        446   \n",
        "101            0.67              160           430      ...        446   \n",
        "102            0.68              159           429      ...        446   \n",
        "103            0.68              159           431      ...        446   \n",
        "104            0.67              159           430      ...        446   \n",
        "105            0.70              160           428      ...        446   \n",
        "106            0.68              158           431      ...        446   \n",
        "\n",
        "     SR_5_total_score  SR_5_fa_rep  SR_5_hbond_sc  SR_5_all_cst  \\\n",
        "94              74.41        78.02          -1.16          0.00   \n",
        "95              71.55        76.12          -1.28          0.00   \n",
        "96              39.87        43.48          -1.50          0.02   \n",
        "97              83.12        86.85          -1.14          0.00   \n",
        "98              75.63        79.31          -1.16          0.00   \n",
        "99              67.84        71.63          -1.24          0.00   \n",
        "100             75.56        79.31          -1.16          0.00   \n",
        "101             75.56        79.31          -1.16          0.00   \n",
        "102             75.56        79.31          -1.16          0.00   \n",
        "103             75.56        79.31          -1.16          0.00   \n",
        "104             75.56        79.31          -1.16          0.00   \n",
        "105             75.56        79.31          -1.16          0.00   \n",
        "106             75.56        79.31          -1.16          0.00   \n",
        "\n",
        "     SR_5_interf_E_1_2  SR_5_dsasa_1_2  SR_5_hbond_pm  SR_5_burunsat_pm  \\\n",
        "94              148.82            0.95              3                 2   \n",
        "95              143.11            0.95              4                 1   \n",
        "96               79.73            0.91              5                 1   \n",
        "97              166.24            0.94              3                 2   \n",
        "98              151.26            0.95              3                 2   \n",
        "99              135.67            0.94              4                 1   \n",
        "100             151.12            0.95              3                 2   \n",
        "101             151.12            0.95              3                 2   \n",
        "102             151.12            0.95              3                 2   \n",
        "103             151.12            0.95              3                 2   \n",
        "104             151.12            0.95              3                 2   \n",
        "105             151.12            0.95              3                 2   \n",
        "106             151.12            0.95              3                 2   \n",
        "\n",
        "     description  \n",
        "94    w407r_0001  \n",
        "95     q19s_0001  \n",
        "96    w399s_0001  \n",
        "97    p329w_0001  \n",
        "98    m323k_0001  \n",
        "99    g355a_0001  \n",
        "100   v147s_0001  \n",
        "101   m261e_0001  \n",
        "102   t218a_0001  \n",
        "103   e423s_0001  \n",
        "104    i91e_0001  \n",
        "105    s17a_0001  \n",
        "106   t175r_0001  \n",
        "\n",
        "[13 rows x 62 columns]"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bgl_y = bgl['eff']\n",
      "bgl_X = bgl.drop('eff', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bgl_X = sklearn.preprocessing.normalize(bgl_X._get_numeric_data())\n",
      "bgl_y = sklearn.preprocessing.scale(bgl_y)\n",
      "\n",
      "bgl_y_test = bgl_y[10:]\n",
      "bgl_y_train = bgl_y[11:]\n",
      "bgl_X_test = bgl_X[10:]\n",
      "bgl_X_train = bgl_X[11:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bgl_y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 187,
       "text": [
        "86"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr = sklearn.linear_model.LinearRegression()\n",
      "regr.fit(bgl_X_train, bgl_y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.coef_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "(59,)"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr.score(bgl_X_test, bgl_y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "0.12115979747744599"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = svm.SVC(kernel='linear')\n",
      "svc.fit(bgl_X_train, bgl_y_train) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 193,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc.score(bgl_X_test, bgl_y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "continuous is not supported",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-194-a2392d7a4f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgl_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgl_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/Cellar/python3/3.4.1/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python3/3.4.1/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_clf_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multilabel-indicator'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/Cellar/python3/3.4.1/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36m_check_clf_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    125\u001b[0m     if (y_type not in [\"binary\", \"multiclass\", \"multilabel-indicator\",\n\u001b[1;32m    126\u001b[0m                        \"multilabel-sequences\"]):\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
       ]
      }
     ],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import gaussian_process"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gp = gaussian_process.GaussianProcess()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gp.fit(bgl_X_train, bgl_y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "GaussianProcess(beta0=None,\n",
        "        corr=<function squared_exponential at 0x115da51e0>, normalize=True,\n",
        "        nugget=array(2.220446049250313e-15), optimizer='fmin_cobyla',\n",
        "        random_start=1,\n",
        "        random_state=<mtrand.RandomState object at 0x1117aea50>,\n",
        "        regr=<function constant at 0x115da5158>, storage_mode='full',\n",
        "        theta0=array([[ 0.1]]), thetaL=None, thetaU=None, verbose=False)"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred, sigma2_pred = gp.predict(bgl_X_test, eval_MSE=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "array([ 0.07955379,  1.28655077, -0.58220439,  1.51247487,  3.19162635,\n",
        "        1.13397718,  0.40692202,  0.54416863, -0.50224369, -0.23545521,\n",
        "        1.48476312, -0.34126639,  1.117426  , -0.60424843, -0.55669134,\n",
        "        1.55061091, -0.39724748,  0.32683437,  1.2475249 ,  0.77343187,\n",
        "        0.39980496, -0.60612888,  0.37663706,  0.65413764,  0.68549157,\n",
        "       -0.44182551,  0.39832879, -0.59350476, -0.44472926, -0.3256277 ,\n",
        "        0.32947421, -0.17274116, -0.39965249, -0.10900233, -0.60598142,\n",
        "       -0.59561293, -0.17996474, -0.1659507 ,  0.51365628, -0.31625851,\n",
        "       -0.49876566,  0.20939319, -0.60412995,  0.00876918, -0.60824798,\n",
        "       -0.56335993, -0.23969816, -0.50350927, -0.60152573, -0.27971837,\n",
        "       -0.61028987, -0.03738513, -0.60324496,  5.76779922, -0.59860642,\n",
        "       -0.60949643, -0.5401812 , -0.59750093, -0.59925804, -0.60998243,\n",
        "       -0.5997888 , -0.6104176 , -0.6104176 , -0.6104176 , -0.6104176 ,\n",
        "       -0.6104176 , -0.6104176 , -0.6104176 , -0.6104176 , -0.6104176 ,\n",
        "       -0.6104176 , -0.6104176 , -0.6104176 , -0.6104176 , -0.6104176 ,\n",
        "       -0.6104176 , -0.6104176 , -0.6102769 , -0.6102689 , -0.60977184,\n",
        "       -0.60250846, -0.54820623, -0.54602411, -0.53663417, -0.52987979,\n",
        "       -0.51853546])"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "86"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}